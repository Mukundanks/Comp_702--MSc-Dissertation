# -*- coding: utf-8 -*-
"""densenet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11T2fG8AY2NRFky8lawl-Kg88zKNMla3N
"""

# !git clone https://github.com/Mukundanks/Comp-702.git



import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import models
from torch.utils.data import DataLoader, Dataset
import torch.utils.data as utils
from torchvision import transforms
from torchsampler import ImbalancedDatasetSampler

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# %matplotlib inline

import warnings

warnings.filterwarnings("ignore")

import numpy as np  
import pandas as pd  
import os
import os, sys
import skimage.io
from skimage.transform import resize
from imgaug import augmenters as iaa
from tqdm import tqdm
import PIL
from PIL import Image, ImageOps
import cv2
from sklearn.utils import class_weight, shuffle
from sklearn.metrics import f1_score, fbeta_score
from sklearn.model_selection import train_test_split
import seaborn as sns
import shutil



from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import cohen_kappa_score

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import roc_curve
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import f1_score
from sklearn.metrics import precision_recall_curve
from torchsummary import summary
from sklearn.metrics import f1_score

import pretrainedmodels

IMAGE_SHAPE = 300

dtype = torch.FloatTensor
# dtype = torch.cuda.FloatTensor

img_size = 300

img_dir = "../input/aptos2019-blindness-detection/train_images/"

data = pd.read_csv("../input/aptos2019-blindness-detection/train.csv")
data.head()

# Distribution of Training Data
display(data['diagnosis'].value_counts())
sns.countplot(data['diagnosis'], color='blue')

image_s = 300 
def crop(image,tolerance=7):
    if image.ndim ==2:
        mask_img = image>tolerance
        return image[np.ix_(mask_img.any(1),mask_img.any(0))]
    elif image.ndim==3:
        image_grey = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        mask_img = image_grey>tolerance
        
        shape_chk = image[:,:,0][np.ix_(mask_img.any(1),mask_img.any(0))].shape[0]
        if (shape_chk == 0): 
            return image 
        else:
            image1=image[:,:,0][np.ix_(mask_img.any(1),mask_img.any(0))]
            image2=image[:,:,1][np.ix_(mask_img.any(1),mask_img.any(0))]
            image3=image[:,:,2][np.ix_(mask_img.any(1),mask_img.any(0))]
            image = np.stack([image1,image2,image3],axis=-1)
        return image
def img_preprocess(image_f):
    image = cv2.imread(image_f)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = crop(image)
    image = cv2.resize(image, (image_s,image_s))
    return image

"""blur images"""

fig=plt.figure(figsize=(9, 9))
img_p = data.loc[8,'id_code']
img_number = data.loc[8,'diagnosis']
image =img_preprocess(f'../input/aptos2019-blindness-detection/train_images/{img_p}.png')
plt.title(f'diagnosis:{img_number} index:{26}')
plt.imshow(image)
plt.tight_layout()

"""dropping blurry images"""

def clear_img(image, t_hold = 60):
    return cv2.Laplacian(image, cv2.CV_64F).var() > t_hold

"""finding blur images"""

def sampleImages(dataframe, c=4, r=3):
    fig=plt.figure(figsize=(5*c, 4*r))
    for value in range(c*r):
        index = np.random.randint(0, len(dataframe)-1, 1)[0]
        img_p = dataframe.loc[index,'id_code']
        img_number = dataframe.loc[index,'diagnosis']
        image = img_preprocess(f'../input/aptos2019-blindness-detection/train_images/{img_p}.png')
        fig.add_subplot(r, c, value+1)
        plt.title(f'diagnosis:{img_number}   Clear:{clear_img(image)}')
        plt.imshow(image)
    plt.tight_layout()
sampleImages(data)

"""dropping blur images"""

import time as tm
bl_l = []
bl_l_number = []
st_t = tm.time();
for t, img_number in enumerate(tqdm(data['id_code'])):
    image = img_preprocess(f'../input/aptos2019-blindness-detection/train_images/{img_number}.png')
    if(not clear_img(image)):
        bl_l.append(t)
        bl_l_number.append(img_number)
data = data.drop(bl_l)
print(f'Time taken: {tm.time() - st_t}:.3% seconds');

"""see the number of dropped images"""

x = len(bl_l_number)
print(f'Dropped values:{x}')

"""displaying the dropped images"""

def image_blr(dataframe, image_i_l, c=4, r=3):
    fig=plt.figure(figsize=(5*c, 4*r))
    for value in range(c*r):
        image = img_preprocess(f'../input/aptos2019-blindness-detection/train_images/{image_i_l[value]}.png')
        fig.add_subplot(r, c, value+1)
        plt.title(f'index:{value}  isclear:{clear_img(image)}')
        plt.imshow(image)
    plt.tight_layout()
image_blr(data, bl_l_number)

import os
len(os.listdir(f'../input/aptos2019-blindness-detection/train_images/'))

data

#moving images based on the class

no = data[data.diagnosis == 0]
mild = data[data.diagnosis == 1]
moderate = data[data.diagnosis == 2]
severe = data[data.diagnosis == 3]
dr = data[data.diagnosis == 4]

def seperation(data):
  file_path = []
  for f in range(len(data)):
      file = data.id_code.iloc[f]
      file = img_dir + file + '.png'
      file_path.append(file)
  return file_path

no = seperation(no)
mild = seperation(mild)
moderate = seperation(moderate)
severe = seperation(severe)
dr = seperation(dr)

len(no) + len(mild) + len(moderate) + len(severe) + len(dr) == len(data)

try:
    os.mkdir('train')
    os.mkdir("train/no")
    os.mkdir("train/mild")
    os.mkdir("train/moderate")
    os.mkdir("train/severe")
    os.mkdir("train/dr")
except:
    pass

def move(path, dst='train/no'):
  for old_path in path:
      name = old_path.split('/')
      name = name[-1]
      shutil.copy(old_path, f'{dst}/{name}')
move(no)
move(mild, dst='train/mild')
move(moderate, dst='train/moderate')
move(severe, dst='train/severe')
move(dr, dst='train/dr')

import splitfolders

splitfolders.ratio('./train/', output="output", seed=1337, ratio=(0.8, 0.0,0.2))

def crop(image,tolerance=7):
    mask_img = image>tolerance
    return image[np.ix_(mask_img.any(1),mask_img.any(0))]

def grey_crop(image,tolerance=7):
    if image.ndim ==2:
        mask_img = image>tolerance
        return image[np.ix_(mask_img.any(1),mask_img.any(0))]
    elif image.ndim==3:
        image_grey = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        mask_img = image_grey>tolerance
        
        shape_chk = image[:,:,0][np.ix_(mask_img.any(1),mask_img.any(0))].shape[0]
        if (shape_chk == 0): 
            return image 
        else:
            image1=image[:,:,0][np.ix_(mask_img.any(1),mask_img.any(0))]
            image2=image[:,:,1][np.ix_(mask_img.any(1),mask_img.any(0))]
            image3=image[:,:,2][np.ix_(mask_img.any(1),mask_img.any(0))]
            image = np.stack([image1,image2,image3],axis=-1)
        return image

def img_colr(image, sigmaX=50):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = grey_crop(image)
    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
    image=cv2.addWeighted (image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)   
    return image

def cir_crp(image, sigmaX=10):   
    image=img_colr(img,sigmaX=50)
    return image



try:
    mkdir preprocessed
    mkdir ./preprocessed/train
    mkdir ./preprocessed/train/no
    mkdir ./preprocessed/train/mild
    mkdir ./preprocessed/train/moderate
    mkdir ./preprocessed/train/dr
    mkdir ./preprocessed/train/severe
except:
    pass

import os
from os import listdir
import shutil

classes=['dr', 'mild', 'moderate', 'no', 'severe']
for x in classes:
    fld_d = "./output/train/"
    pt_1=os.path.join(fld_d,x)
    for img in os.listdir(pt_1):
        if (img.endswith(".png")): 
            i_Path=os.path.join(pt_1,img)
            f_info=img
            img = cv2.imread(i_Path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (IMAGE_SHAPE, IMAGE_SHAPE))
            img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , IMAGE_SHAPE/10) ,-4 ,128)
            dest_dir= "./preprocessed/train/"
            pt_2=os.path.join(dest_dir,x,f_info)
            cv2.imwrite(pt_2,image)


# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img = mpimg.imread(r'./preprocessed/train/mild/db4ed1e07aa3.png')
imgplot = plt.imshow(img)
plt.show()

try:
    mkdir preprocessed
    mkdir ./preprocessed/val
    mkdir ./preprocessed/val/no
    mkdir ./preprocessed/val/mild
    mkdir ./preprocessed/val/moderate
    mkdir ./preprocessed/val/dr
    mkdir ./preprocessed/val/severe
except:
    pass

classes=['dr', 'mild', 'moderate', 'no', 'severe']
for x in classes:
    fld_d = "./output/val/"
    pt_1=os.path.join(fld_d,x)
    for img in os.listdir(pt_1):
        if (img.endswith(".png")): 
            i_Path=os.path.join(pt_1,img)
            f_info=img
            img = cv2.imread(i_Path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (IMAGE_SHAPE, IMAGE_SHAPE))
            img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , IMAGE_SHAPE/10) ,-4 ,128)
            dest_dir= "./preprocessed/val/"
            pt_2=os.path.join(dest_dir,x,f_info)
            cv2.imwrite(pt_2,image)

try:
    mkdir preprocessed
    mkdir ./preprocessed/test
    mkdir ./preprocessed/test/no
    mkdir ./preprocessed/test/mild
    mkdir ./preprocessed/test/moderate
    mkdir ./preprocessed/test/dr
    mkdir ./preprocessed/test/severe
except:
    pass

classes=['dr', 'mild', 'moderate', 'no', 'severe']
for x in classes:
    fld_d = "./output/test/"
    pt_1=os.path.join(fld_d,x)
    for img in os.listdir(pt_1):
        if (img.endswith(".png")): 
            i_Path=os.path.join(pt_1,img)
            f_info=img
            img = cv2.imread(i_Path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (IMAGE_SHAPE, IMAGE_SHAPE))
            img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , IMAGE_SHAPE/10) ,-4 ,128)
            dest_dir= "./preprocessed/test/"
            pt_2=os.path.join(dest_dir,x,f_info)
            cv2.imwrite(pt_2,image)

train_dir = './preprocessed/train'
val_dir = './preprocessed/val'
test_dir = './preprocessed/test'



crop_size = 255
transformations = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Resize(crop_size),
        torchvision.transforms.CenterCrop(crop_size),
        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

batch_size = 4

train_data = torchvision.datasets.ImageFolder(root=train_dir, transform=transformations)
train_data = torch.utils.data.DataLoader(train_data, sampler=ImbalancedDatasetSampler(train_data),batch_size=batch_size,
                                          shuffle=False, num_workers=2)

test_data = torchvision.datasets.ImageFolder(root=test_dir, 
                                        transform=transformations)
test_data = torch.utils.data.DataLoader(test_data, batch_size=batch_size,
                                         shuffle=True, num_workers=2)

classes = ('0','1','2','3','4')

test_data.dataset.classes

def samples(image):
    image = image / 2 + 0.5     
    np_image = image.numpy()
    plt.imshow(np.transpose(np_image, (1, 2, 0)))
    plt.show()
dataiter = iter(train_data)
images, output = next(dataiter)
samples(torchvision.utils.make_grid(images))
print(' '.join(f'{classes[output[x]]:5s}' for x in range(batch_size)))

device = ['cuda','cpu']

"""pre-trained models"""



print(pretrainedmodels.model_names)

"""available parameters in a model

"""

from densenet_pytorch import DenseNet 
model = DenseNet.from_pretrained('densenet121')

model.classifier = nn.Linear(1024,5)

#tracking with neptune API
run = neptune.init(
    project="mukundanks/DR-702",
    api_token="eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YTM2ZmU2NS1kM2RmLTRkMTAtOTJkOC1iMDk5Yzg3ZDI1M2MifQ==",
)

run["algorithm"] = "densenet"

params = {
    "loss": "CrossEntropyLoss",
    "learning_rate": 0.01,
    "n_epochs": 60,
    "batch_size":5
}

run["model/parameters"] = params
monitoring = True

#Defining devices
device = device[0]

model = model.to(device)
#Defining loss and optimiser
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


#training the model

list_loss = []
list_acuracy = []
accuracy = 0
acuracy_max = 0
running_loss = 0.0
print(len(test_data))
for epoch in range(100):
  with tqdm(train_data, unit="iteration") as train_epoch:
    train_epoch.set_description(f"Epoch {epoch}")
    for step, data in enumerate(train_epoch):
        
        #obtaining input and labels
        inputs, labels = data
        inputs,  labels = inputs.to(device), labels.to(device)

        #forward and backward
        optimizer.zero_grad()

        outputs = model(inputs)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()

        #computing statistics
        running_loss += loss.item()
        outputs = torch.argmax(outputs, 1)
        accuracy = (outputs == labels).float().mean()
        train_epoch.set_postfix(loss=loss.item(), accuracy=100*accuracy.item())
        if monitoring:
            run["Training_loss"].log(loss.item())
            run["Training_acc"].log(accuracy)
        
        list_acuracy.append(accuracy.item())
        list_loss.append(loss.item())
        #saving the best model

        if accuracy < acuracy_max:
            torch.save(model, f'model_resnet.pth')
            acuracy_max = accuracy 

print('Finished Training')

len(images)

model
#loading the trained model

modelp = torch.load('/kaggle/input/densenet-1/model_densenet.pth')
modelp = modelp.to(device)

#iterating through the test dataset to see the ground truth
dataiter = iter(test_data)
images, labels = next(dataiter)
print('GroundTruth: ', ' '.join(f'{classes[labels[m]]:5s}' for m in range(4)))

images, labels = images.to(device), labels.to(device)

outputs = modelp(images)
#finding predicted values

null, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join(f'{classes[predicted[m]]:5s}'
                              for m in range(4)))

#checking with whole dataset
cr_pred = 0
label_count = 0
with torch.no_grad():
    for data in test_data:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = modelp(images)
        null, predicted = torch.max(outputs.data, 1)
        label_count += labels.size(0)
        cr_pred += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10 test images: {100 * cr_pred // label_count} %')

#checking eah class accuracy
correct_pred = {c: 0 for c in classes}
total_pred = {c: 0 for c in classes}

with torch.no_grad():
    for data in test_data:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = modelp(images)
        null, predictions = torch.max(outputs, 1)
      
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1



for classes, corr_values in correct_pred.items():
    accuracy = 100 * float(corr_values) / total_pred[classes]
    print(f'Accuracy for class: {classes:5s} is {accuracy:.1f} %')

##confusion matrix and saving output

from sklearn.metrics import confusion_matrix
import seaborn as sn
import pandas as pd

prediction = []
truevalue = []
modelp = modelp.to('cpu')


for inputs, labels in test_data:
        images = inputs
        labels = labels
        output = modelp(images) 

        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
        prediction.extend(output) 
        
        labels = labels.data.cpu().numpy()
        truevalue.extend(labels)


classes = ('0','1','2','3','4')

cm = confusion_matrix(truevalue, prediction)
confusion = pd.DataFrame(cm/np.sum(cm) *10, index = [i for i in classes],
                     columns = [i for i in classes])
plt.figure(figsize = (12,7))
sn.heatmap(confusion, annot=True)
plt.savefig('output.png')
#finding precision, recall and f1 score

precision_score(truevalue, prediction, average = 'weighted')
#weightted precision is accuracy

precision_score(truevalue, prediction, average = 'macro')

recall_score(truevalue, prediction, average = 'macro')

f1_score(truevalue, prediction, average='macro')
#finding specificity and sensitivity

FP = confusion.sum(axis=0) - np.diag(confusion)  
FN = confusion.sum(axis=1) - np.diag(confusion)
TP = np.diag(confusion)
TN = confusion.values.sum() - (FP + FN + TP)

# Sensitivity
TPR = TP/(TP+FN)
# Specificity
TNR = TN/(TN+FP) 
# Precision 
PPV = TP/(TP+FP)
# Negative predictive value
NPV = TN/(TN+FN)
# false positive rate
FPR = FP/(FP+TN)
# False negative rate
FNR = FN/(TP+FN)
# False discovery rate
FDR = FP/(TP+FP)

# Overall accuracy
ACC = (TP+TN)/(TP+FP+FN+TN)
print(f' Accuracy for each class is: \n {ACC}')
print(f'Sensitivity is : \n{TPR}')
print(f'specificity is : \n{TNR}')

#confusion matrix based heatmap
cm = confusion_matrix(truevalue, prediction)

cm_display = ConfusionMatrixDisplay(cm).plot()

target_names = train_data.dataset.classes
print(classification_report(truevalue, prediction, target_names=target_names))

sns.heatmap(confusion_matrix(truevalue, prediction), 
            annot=True, fmt="d", cbar = False, cmap = plt.cm.PuBu, )

#model summary
modelp = modelp.to("cpu")
summary(modelp, (3,255,255))

#multilabel confusion matrix
multilabel_confusion_matrix(truevalue, prediction)

